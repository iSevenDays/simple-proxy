# Claude Code Proxy Model Configuration
# 
# Configure which models and endpoints to use for Claude Code requests.
# Copy this file to .env and customize as needed.
# 
# ALL MODELS AND ENDPOINTS ARE REQUIRED - no fallbacks when .env exists

# BIG_MODEL: Used for Claude Sonnet requests (high-capability tasks)
BIG_MODEL=your-big-model-name
BIG_MODEL_ENDPOINT=http://192.168.0.24:8080/v1/chat/completions
BIG_MODEL_API_KEY=sk-your-api-key

# SMALL_MODEL: Used for Claude Haiku requests (fast, lightweight tasks)  
SMALL_MODEL=qwen2.5-coder:latest
SMALL_MODEL_ENDPOINT=http://192.168.0.46:11434/v1/chat/completions
SMALL_MODEL_API_KEY=ollama

# CORRECTION_MODEL: Used for tool call correction service
CORRECTION_MODEL=qwen2.5-coder:latest
TOOL_CORRECTION_ENDPOINT=http://192.168.0.46:11434/v1/chat/completions
TOOL_CORRECTION_API_KEY=ollama

# SKIP_TOOLS: Comma-separated list of tool names to skip/filter out (optional)
# Example: SKIP_TOOLS=NotebookRead,NotebookEdit,SomeOtherTool
SKIP_TOOLS=NotebookRead,NotebookEdit

# HANDLE_EMPTY_TOOL_RESULTS: Replace empty tool results with descriptive messages (optional)
# Set to "true" or "1" to enable (recommended), "false" or "0" to disable
HANDLE_EMPTY_TOOL_RESULTS=true

# HANDLE_EMPTY_USER_MESSAGES: Replace empty user messages with placeholder content (optional)
# Set to "true" or "1" to enable, "false" or "0" to disable (default: false)
HANDLE_EMPTY_USER_MESSAGES=false

# PRINT_SYSTEM_MESSAGE: Print system messages to logs for debugging (optional)
# Set to "true" or "1" to enable, anything else (or omit) to disable
PRINT_SYSTEM_MESSAGE=false

# PRINT_TOOL_SCHEMAS: Print tool schemas from Claude Code requests for debugging (optional)
# Set to "true" or "1" to enable, anything else (or omit) to disable
# Useful for debugging tool schema mismatches between Claude Code and Simple Proxy
PRINT_TOOL_SCHEMAS=false

# Examples of other configurations:
# BIG_MODEL=kimi-k2
# BIG_MODEL_ENDPOINT=http://localhost:8080/v1/chat/completions
# BIG_MODEL_API_KEY=sk-your-kimi-key
# SMALL_MODEL=llama-3.1-8b-instruct
# SMALL_MODEL_ENDPOINT=http://localhost:11434/v1/chat/completions
# SMALL_MODEL_API_KEY=ollama
# CORRECTION_MODEL=llama-3.1-8b-instruct