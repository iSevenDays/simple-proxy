# Claude Code Proxy Model Configuration
# 
# Configure which models and endpoints to use for Claude Code requests.
# Copy this file to .env and customize as needed.
# 
# ALL MODELS AND ENDPOINTS ARE REQUIRED - no fallbacks when .env exists
# 
# MULTI-ENDPOINT SUPPORT: Endpoints support comma-separated lists for failover
# Examples: http://192.168.0.46:11434/v1/chat/completions,http://192.168.0.50:11434/v1/chat/completions
# The proxy will round-robin between endpoints and failover on errors

# BIG_MODEL: Used for Claude Sonnet requests (high-capability tasks)
BIG_MODEL=your-big-model-name
BIG_MODEL_ENDPOINT=http://192.168.0.24:8080/v1/chat/completions,http://192.168.0.50:8080/v1/chat/completions
BIG_MODEL_API_KEY=sk-your-api-key

# SMALL_MODEL: Used for Claude Haiku requests (fast, lightweight tasks)  
SMALL_MODEL=qwen2.5-coder:latest
SMALL_MODEL_ENDPOINT=http://192.168.0.46:11434/v1/chat/completions,http://192.168.0.50:11434/v1/chat/completions
SMALL_MODEL_API_KEY=ollama

# CORRECTION_MODEL: Used for tool call correction service
CORRECTION_MODEL=qwen2.5-coder:latest
TOOL_CORRECTION_ENDPOINT=http://192.168.0.46:11434/v1/chat/completions,http://192.168.0.50:11434/v1/chat/completions
TOOL_CORRECTION_API_KEY=ollama

# SKIP_TOOLS: Comma-separated list of tool names to skip/filter out (optional)
# Example: SKIP_TOOLS=NotebookRead,NotebookEdit,SomeOtherTool
SKIP_TOOLS=NotebookRead,NotebookEdit

# HANDLE_EMPTY_TOOL_RESULTS: Replace empty tool results with descriptive messages (optional)
# Set to "true" or "1" to enable (recommended), "false" or "0" to disable
HANDLE_EMPTY_TOOL_RESULTS=true

# HANDLE_EMPTY_USER_MESSAGES: Replace empty user messages with placeholder content (optional)
# Set to "true" or "1" to enable, "false" or "0" to disable (default: false)
HANDLE_EMPTY_USER_MESSAGES=false

# PRINT_SYSTEM_MESSAGE: Print system messages to logs for debugging (optional)
# Set to "true" or "1" to enable, anything else (or omit) to disable
PRINT_SYSTEM_MESSAGE=false

# PRINT_TOOL_SCHEMAS: Print tool schemas from Claude Code requests for debugging (optional)
# Set to "true" or "1" to enable, anything else (or omit) to disable
# Useful for debugging tool schema mismatches between Claude Code and Simple Proxy
PRINT_TOOL_SCHEMAS=false

# CONVERSATION_LOGGING_ENABLED: Enable full conversation logging to files (optional)
# Set to "true" or "1" to enable, "false" or "0" to disable (default: false)
# Creates detailed logs of all requests, responses, tool calls, and corrections
CONVERSATION_LOGGING_ENABLED=false

# CONVERSATION_LOG_LEVEL: Log level for conversation logs (optional)
# Valid values: DEBUG, INFO, WARN, ERROR (default: INFO)
# Controls the verbosity of conversation logging
CONVERSATION_LOG_LEVEL=INFO

# CONVERSATION_MASK_SENSITIVE: Mask sensitive data in conversation logs (optional)
# Set to "true" or "1" to enable (default), "false" or "0" to disable
# Protects API keys and other sensitive information in log files
CONVERSATION_MASK_SENSITIVE=true

# ENABLE_TOOL_CHOICE_CORRECTION: Enable tool choice correction and necessity detection (optional)
# Set to "true" or "1" to enable, "false" or "0" to disable (default: false)
# Uses hybrid classifier to detect when tools are actually needed in responses
ENABLE_TOOL_CHOICE_CORRECTION=false

# Examples of other configurations:
# BIG_MODEL=kimi-k2
# BIG_MODEL_ENDPOINT=http://localhost:8080/v1/chat/completions
# BIG_MODEL_API_KEY=sk-your-kimi-key
# SMALL_MODEL=llama-3.1-8b-instruct
# SMALL_MODEL_ENDPOINT=http://localhost:11434/v1/chat/completions
# SMALL_MODEL_API_KEY=ollama
# CORRECTION_MODEL=llama-3.1-8b-instruct